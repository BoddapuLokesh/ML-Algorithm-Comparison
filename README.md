# ML Algorithm Comparison and Insight Tool

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-green.svg)](https://flask.palletsprojects.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.4+-orange.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A Flask web app for automated Exploratory Data Analysis (EDA) and quick ML model comparison, with secure server-rendered previews and exports.

## ğŸ“‹ Table of Contents

- Features
- Quick Start
- Installation
- Usage
- Project Structure
- API
- Supported Algorithms
- Configuration
- Troubleshooting
- Contributing
- License
- Changelog

## ğŸš€ Features

- Automated EDA: dataset size, dtypes, missingness, duplicates, memory usage
- Smart target detection and problem-type inference (binary/multiclass vs regression)
- One-click training and comparison across multiple sklearn models
- Feature importance visualization and downloadable model package (model + preprocessors)
- CSV export of model comparison results
- Secure, server-generated HTML for data preview to minimize XSS attack surface

## ğŸƒ Quick Start

### macOS/Linux (zsh) â€” copy & paste

```bash
# 1) Clone the repository (replace with your repo URL)

git clone https://github.com/BoddapuLokesh/ML-Algorithm-Comparison.git
cd ML-Algorithm-Comparison

# 2) Create and activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 3) Install dependencies
python -m pip install --upgrade pip
pip install -r requirements.txt

# 4) Run the application
python app.py
# App will start at http://127.0.0.1:5002/
```

If you already have the folder locally, start from step 2 inside the project directory.

### Windows (PowerShell)

```powershell
# 1) Clone the repository (replace with your repo URL)
git clone https://github.com/BoddapuLokesh/ML-Algorithm-Comparison.git
cd ML-Algorithm-Comparison

# 2) Create and activate a virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 3) Install dependencies
python -m pip install --upgrade pip
pip install -r requirements.txt

# 4) Run the application
python app.py
# App will start at http://127.0.0.1:5002/
```

## ğŸ“¦ Installation

Prerequisites:
- Python 3.8+
- pip

Steps:
1) Clone the repository
2) Create and activate a virtual environment
3) Install dependencies: `pip install -r requirements.txt`
4) Run the app: `python app.py`

Optional verification:
```bash
python -c "import flask, pandas, sklearn; print('Deps OK')"
```

## ğŸ’¡ Usage

1) Upload a CSV/XLSX/XLS (max 50MB) to see a safe, server-generated preview
2) Click Analyze to compute EDA (stats, missingness, correlations)
3) Choose the target and confirm problem type (auto-detected; you can override)
4) Start training to compare models; the best model is selected automatically
5) Review metrics and feature importance; export CSV or download the model package

## ğŸ—ï¸ Project Structure

```
ML-Algorithm-Comparison/
â”œâ”€â”€ app.py                # Flask routes: upload, EDA, training, exports
â”œâ”€â”€ app_helpers.py        # JSON envelope, guards, upload/EDA/train handlers
â”œâ”€â”€ model_utils.py        # Back-compat facade to ml_utils/*
â”œâ”€â”€ ml_utils/
â”‚   â”œâ”€â”€ config.py         # MLConfig, typed results, preview HTML
â”‚   â”œâ”€â”€ eda.py            # Minimal+enhanced EDA
â”‚   â”œâ”€â”€ models.py         # AutoMLComparer (fit, score, select, importance)
â”‚   â”œâ”€â”€ preprocessing.py  # ColumnTransformer pipelines + fallback
â”‚   â””â”€â”€ utils.py          # JSON safety, validations, detection
â”œâ”€â”€ templates/            # Jinja templates (layout/index)
â”œâ”€â”€ static/               # style.css, app.js
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸ“š API

File upload and EDA
- POST `/` â€” Upload dataset (AJAX)
- POST `/process_eda` â€” Run EDA and return stats/auto target/type
- GET `/eda` â€” EDA JSON (server-side cached)
- GET `/data_preview` â€” Preview JSON
- GET `/get_data_preview_html` â€” Secure HTML preview

Training and results
- POST `/validate_training_config` â€” Validate target/type/split
- POST `/train` â€” Train, compare, and return metrics/results/importance
- GET `/metrics` â€” Best model metrics
- GET `/best_model` â€” Best model name + metrics
- GET `/model_comparison` â€” All trained models and metrics
- GET `/feature_importance` â€” Feature importance data

Utilities
- POST `/analyze_target` â€” Inspect a chosen target column
- POST `/calculate_split` â€” Convert split ratio to percentages
- GET `/download_model` â€” ZIP: model.joblib + preprocessors.joblib + README
- GET `/export_results` â€” CSV export of all models
- GET `/debug_session` â€” Inspect session keys (debug)
- POST `/reset_session` â€” Clear session/caches (debug)

Notes
- JSON shapes vary by endpoint; on errors youâ€™ll receive `{ "success": false, "error": "..." }`.

## ğŸ¤– Supported Algorithms

Classification: Logistic Regression, Random Forest, Gradient Boosting, SVC, Decision Tree

Regression: Linear Regression, Random Forest, Gradient Boosting, SVR, Decision Tree

Metrics
- Classification: Accuracy, Precision, Recall, F1, Training Time
- Regression: RÂ², MSE, Training Time

## âš™ï¸ Configuration

Environment (optional)
```bash
export FLASK_ENV=development
export FLASK_DEBUG=1
```

Runtime settings
- Max upload size: 50MB
- Session lifetime: 1 hour
- Model timeout (default): 300s per model (see `MLConfig`)

Customization
- Adjust preprocessing or defaults in `ml_utils/*.py`

## ğŸ”§ Troubleshooting

- `.xls` files require `xlrd==1.2.0` (installed via requirements.txt)
- Very large/wide datasets: correlations are capped to reduce memory use
- If a model hits the time budget, itâ€™s skipped; consider sampling or simpler models

## ğŸ¤ Contributing

Small PRs are welcome. Please open an issue first if the change is substantial.

## ğŸ“„ License

MIT

## ğŸ“ Changelog

August 2025
- Server-side preview HTML and consolidated Python validations
- AutoMLComparer pipelines and improved EDA (memory usage, quality score)
- Model export (model + preprocessors) and CSV results export
